{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c0c3f6",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a776de6",
   "metadata": {},
   "source": [
    "### Chain Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85a64f",
   "metadata": {},
   "source": [
    "1. x : input\n",
    "2. z : output\n",
    "3. y : outout for a(x) and input for b(y)\n",
    "4. a(x) and b(x) are functions/operations\n",
    "5. |   | : Nodes\n",
    "\n",
    "x --> | a(x) | --> y --> | b(y) | --> z\n",
    "\n",
    "Now we want to minimize z, so we need to calculate the derivative dz/dx.\n",
    "\n",
    "According to chain rule: dz/dx = dz/dy . dy/dx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f09e91",
   "metadata": {},
   "source": [
    "### Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2232c1",
   "metadata": {},
   "source": [
    "So, for every operation we do with our tensors, pytorch will create a graph for us.\n",
    "So, over at each node we apply one operation/function with some inputs and then get an output.\n",
    "\n",
    "Here, x and y are inputs and we multiply them and get z as output\n",
    "\n",
    "<p>x ---↘............................>( dz/dx = d(x.y)/dx = y) [Local gradients]</p>\n",
    "...........| f = x.y | ---> z</p>\n",
    "<p>y ---↗............................>( dz/dy = d(x.y)/dy = x) [Local gradients]</p>\n",
    "\n",
    "Now at these nodes, we can calculate local gradients and we can use them later in the chain rule to get final gradient.\n",
    "We want local gradients because our graph has more operations and at the very end we calculate a loss function that we want to minimize so we have to calculate the gradient of this loss w.r.t x\n",
    "\n",
    "So, d(loss)/dx = d(loss)/dz . dz/dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7686f34",
   "metadata": {},
   "source": [
    "<h3>How to solve d(x.y)/dx like above</h3>\n",
    "\n",
    "d(x.y)/dy\n",
    "\n",
    "= x.dy/dy + y.dx/dy\n",
    "\n",
    "(Since x is treated as a constant with respect to y, dx/dy =0 dy/dy = 1)\n",
    "\n",
    "= x.1 + y.0\n",
    "\n",
    "=x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44f119",
   "metadata": {},
   "source": [
    "### The whole concept now contains 3 steps:\n",
    "1. Forward pass : Compute Loss\n",
    "2. Compute local gradients\n",
    "3. Backward pass : Compute dloss / dweights using chain rule (Here we compute the gradient of loss w.r.t our weights or parameters using chain rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467a9d5",
   "metadata": {},
   "source": [
    "### Linear Regression in terms of NN\n",
    "1. ŷ = w.x\n",
    "2. loss function (Squared Error)= (ŷ - y)^2 = (w.x - y)^2\n",
    "3. ŷ : predicted Value\n",
    "4. y : actual value\n",
    "\n",
    "<p>x ---↘</p>\n",
    "______| * | ---> ŷ ---> | - (minus) | --s--> | ^2 | --> Loss</p>\n",
    "<p>w ---↗________y ---↗</p>\n",
    "\n",
    "Now we want to minimize our loss so we want to know our derivative of our loss w.r.t our weights.\n",
    "\n",
    "So, we apply forward pass and get the loss.\n",
    "\n",
    "Then we calculate the local gradients (dŷ/dx, dŷ/dw, ds/dŷ, d(loss)/ds) at each node\n",
    "\n",
    "And thenwe do a backward pass  d(loss)/ds) -> ds/dŷ -> dŷ/dw (for parameter w). We use the chain rule to get the derivative of loss w.r.t s = d(loss)/ds then with this we calculate d(loss)/dŷ and then the final d(loss)/dw all using chain rule.\n",
    "\n",
    "Notice we don't need to know the derivative of x and y because these are constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfcf860",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bfd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf00eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d437b15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Forward pass and compute the loss\n",
    "y_hat = w*x\n",
    "loss = (y_hat-y)**2\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09887fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backward pass\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf26719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our next steps would be to update weights and do couple of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6d50f",
   "metadata": {},
   "source": [
    "### Let's find out how w.grad is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210278a",
   "metadata": {},
   "source": [
    "1. x = 1\n",
    "2. y = 2\n",
    "3. w = 1\n",
    "4. ŷ = w.x = 1\n",
    "5. s = ŷ - y = 1 - 2 = -1\n",
    "6. loss = s^2 = 1\n",
    "\n",
    "#### Equation1 - solving for d(loss)/dŷ  \n",
    "d(loss)/dŷ  \n",
    "\n",
    "= d(loss)/ds . ds/dŷ\n",
    "\n",
    "= d(s^2)/ds . d(ŷ - y)/dŷ\n",
    "\n",
    "= 2.s.1\n",
    "\n",
    "= -2\n",
    "\n",
    "#### Equation2 - solving for d(loss)/dw\n",
    "d(loss)/dw\n",
    "\n",
    "= d(loss)/dŷ . dŷ/dw\n",
    "\n",
    "= -2 . d(w.x)/dw\n",
    "\n",
    "= -2.x\n",
    "\n",
    "= -2\n",
    "\n",
    "#### Hence w.grad is -2 as we saw it in the above code as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ef198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
